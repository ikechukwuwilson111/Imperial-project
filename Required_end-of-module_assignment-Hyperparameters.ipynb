{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a17b6d5",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20d6f639da468adb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Required end-of-module assignment: Hyperparameters  \n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this assignment, you will compare different models and different hyperparameters to determine the best model in a classification setting.\n",
    "\n",
    "This activity is designed to build your familiarity and comfort coding in Python while also helping you review key topics from each module. As you progress through the activity, questions will get increasingly more complex. It is important that you adopt a programmer's mindset when completing this activity. Remember to run your code from each cell before submitting your activity, as doing so will give you a chance to fix any errors before submitting.\n",
    "\n",
    "\n",
    "\n",
    "### Learning outcome addressed\n",
    "\n",
    "- Apply hyperparameter tuning techniques to a business case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aab3f6",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7aec2a74e02f8212",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Index:\n",
    "\n",
    "- [Question 1](#Question-1)\n",
    "- [Question 2](#Question-2)\n",
    "- [Question 3](#Question-3)\n",
    "- [Question 4](#Question-4)\n",
    "- [Question 5](#Question-5)\n",
    "- [Question 6](#Question-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e72342dd",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ddb354ed7128db3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f9cf7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b59cd08a82f70b61",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The data set\n",
    "\n",
    "The data below contains demographic information extracted from census data in the United States.  The goal of the task is to learn to identify the characteristics of individuals making over 50,000 USD per year in 1994."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41dd85ab",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-576bce4249632209",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Ronny Kohavi and Barry Becker  \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Adult) - 1996  \n",
      "**Please cite**: Ron Kohavi, \"Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid\", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996  \n",
      "\n",
      "Prediction task is to determine whether a person makes over 50K a year. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
      "\n",
      "This is the original version from the UCI repository, with training and test sets merged.\n",
      "\n",
      "### Variable description\n",
      "\n",
      "Variables are all self-explanatory except __fnlwgt__. This is a proxy for the demographic background of the people: \"People with similar demographic characteristics should have similar weights\". This similarity-statement is not transferable across the 51 different states.\n",
      "\n",
      "Description from the donor of the database: \n",
      "\n",
      "The weights on the CPS files are controlled to independent estimates of the civilian noninstitutional population of the US.  These are prepared monthly for us by Population Division here at the Census Bureau. We use 3 sets of controls. These are:\n",
      "1.  A single cell estimate of the population 16+ for each state.\n",
      "2.  Controls for Hispanic Origin by age and sex.\n",
      "3.  Controls by Race, age and sex.\n",
      "\n",
      "We use all three sets of controls in our weighting program and \"rake\" through them 6 times so that by the end we come back to all the controls we used. The term estimate refers to population totals derived from CPS by creating \"weighted tallies\" of any specified socio-economic characteristics of the population. People with similar demographic characteristics should have similar weights. There is one important caveat to remember about this statement. That is that since the CPS sample is actually a collection of 51 state samples, each with its own probability of selection, the statement only applies within state.\n",
      "\n",
      "\n",
      "### Relevant papers  \n",
      "\n",
      "Ronny Kohavi and Barry Becker. Data Mining and Visualization, Silicon Graphics.  \n",
      "e-mail: ronnyk '@' live.com for questions.\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "df_adult = fetch_openml(\n",
    "    'adult', version=2, data_home='./data/scikit_learn_data')\n",
    "print(df_adult.DESCR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30327b39",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7be5a841d0487cfe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "<=50K    0.760718\n",
       ">50K     0.239282\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult.frame['class'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95dda745",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-affd019284ec8589",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X = df_adult.frame.drop('class', axis = 1)\n",
    "y = df_adult.frame['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb13591",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9caac61ace7db69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   age             48842 non-null  int64   \n",
      " 1   workclass       46043 non-null  category\n",
      " 2   fnlwgt          48842 non-null  int64   \n",
      " 3   education       48842 non-null  category\n",
      " 4   education-num   48842 non-null  int64   \n",
      " 5   marital-status  48842 non-null  category\n",
      " 6   occupation      46033 non-null  category\n",
      " 7   relationship    48842 non-null  category\n",
      " 8   race            48842 non-null  category\n",
      " 9   sex             48842 non-null  category\n",
      " 10  capital-gain    48842 non-null  int64   \n",
      " 11  capital-loss    48842 non-null  int64   \n",
      " 12  hours-per-week  48842 non-null  int64   \n",
      " 13  native-country  47985 non-null  category\n",
      "dtypes: category(8), int64(6)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373ed55",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9ee3a2191436343f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:)\n",
    "\n",
    "### Question 1\n",
    "\n",
    "What is the baseline accuracy for the classification task using the majority class from `y`?  Enter your response as a float accurate to three decimal places (between 0 and 1) to `ans1` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05faec4b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c48037fe993e53b7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing the majority class gives accuracy  0.761\n"
     ]
    }
   ],
   "source": [
    "ans1 = None\n",
    "### BEGIN SOLUTION\n",
    "ans1 = 0.760718\n",
    "### END SOLUTION\n",
    "#Answer test\n",
    "print(f'Guessing the majority class gives accuracy {ans1: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df348f8",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-08608e103a7fd407",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ans1_ =  0.760718\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "assert round(ans1, 3) == round(ans1_, 3), 'Check that your answer is between 0 and 1'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91283e20",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a74769578c651b8a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:)\n",
    "\n",
    "### Question 2\n",
    "\n",
    "Use the transformed training data below to perform 5-fold cross-validation with `cross_val_score` and the `LogisticRegression` model `lgr` below. Use accuracy as the default metric and assign the results to `cv_scores_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb9a5d9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e31207d23d26a90",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(random_state=22)\n",
    "transformer = make_column_transformer((OneHotEncoder(), X.select_dtypes('category').columns.tolist()),\n",
    "                                     remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acfc73cd",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4a38c90c3256496",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_transformed = transformer.fit_transform(X_train)\n",
    "X_test_transformed = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e74462a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa9111e241992014",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The basic logistic regression model gives average accuracy:  0.799\n",
      "and deviations  0.0050\n"
     ]
    }
   ],
   "source": [
    "cv_scores_1 = None\n",
    "### BEGIN SOLUTION\n",
    "cv_scores_1 = cross_val_score(lgr, X_train_transformed, y_train, cv = 5)\n",
    "### END SOLUTION\n",
    "#Answer test\n",
    "print(f'''The basic logistic regression model gives average accuracy: {cv_scores_1.mean(): .3f}\n",
    "and deviations {cv_scores_1.std(): .4f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7440d2a3",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b88290901f7588d7",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "cv_scores_1_ = cross_val_score(lgr, X_train_transformed, y_train, cv = 5)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_almost_equal(cv_scores_1, cv_scores_1_, err_msg = 'Make sure your using the transformed data')\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead248fd",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d8a4c1fd06b3c66c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:)\n",
    "\n",
    "### Question 3\n",
    "\n",
    "Use the transformed training data below to perform 5-fold cross-validation with `cross_val_score` and the `RandomForestClassifier` model `forest` below. Use accuracy as the default metric and assign the results to `cv_scores_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c559b9f6",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c28eaf7ab7d46eea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca04c9c9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-54f884cca73c0722",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The basic random forest model gives average accuracy:  0.848\n",
      "and deviations  0.0041\n"
     ]
    }
   ],
   "source": [
    "cv_scores_2 = None\n",
    "### BEGIN SOLUTION\n",
    "cv_scores_2 = cross_val_score(forest, X_train_transformed, y_train, cv = 5)\n",
    "### END SOLUTION\n",
    "#Answer test\n",
    "print(f'''The basic random forest model gives average accuracy: {cv_scores_2.mean(): .3f}\n",
    "and deviations {cv_scores_2.std(): .4f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba5200ef",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4813e977e3f5c643",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "cv_scores_2_ = cross_val_score(forest, X_train_transformed, y_train, cv = 5)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_almost_equal(cv_scores_2, cv_scores_2_, err_msg = 'Make sure your using the transformed data')\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3410e60",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de88fa26857e328f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:)\n",
    "\n",
    "### Question 4\n",
    "\n",
    "While the default forest model seems to do better than both the baseline and logistic model, perhaps you can squeeze some further performance out of the model by tuning the hyperparameters.  Because this is a slow process and may hang up the autograder, the results of searching over hyperparameters are presented as a `DataFrame` below.  Use this dataframe to select the model with the highest average accuracy over the five folds.\n",
    "\n",
    "What was the optimal number of estimators and the best depth parameter based on the average accuracy?  Assign `best_estimator` and `best_depth` as integers below.\n",
    "\n",
    "The code below was used to create and store the search results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba2e9d3",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-379e71a9ac817e4d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "```python\n",
    "#parameters to consider in model\n",
    "params = {'n_estimators': [10, 50, 100], 'max_depth': [1, 2, 3, None]}\n",
    "#grid search and cross validate model with parameters\n",
    "grid = GridSearchCV(forest, param_grid=params)\n",
    "#fit the transformed data\n",
    "grid.fit(X_train_transformed, y_train)\n",
    "#create dataframe of results\n",
    "results_df = pd.DataFrame(grid.cv_results_)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e9ae225",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0239fba3b55f9ebc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66354a5f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e2095135dcbb871",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073660</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>0.015565</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 10}</td>\n",
       "      <td>0.760748</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760722</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.207638</td>\n",
       "      <td>0.027449</td>\n",
       "      <td>0.026752</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 50}</td>\n",
       "      <td>0.760748</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760722</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.396040</td>\n",
       "      <td>0.023567</td>\n",
       "      <td>0.055455</td>\n",
       "      <td>0.013361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 100}</td>\n",
       "      <td>0.760748</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760715</td>\n",
       "      <td>0.760722</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085616</td>\n",
       "      <td>0.015366</td>\n",
       "      <td>0.014412</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 10}</td>\n",
       "      <td>0.778627</td>\n",
       "      <td>0.779143</td>\n",
       "      <td>0.776686</td>\n",
       "      <td>0.779962</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.778439</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277640</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.031804</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.776034</td>\n",
       "      <td>0.775730</td>\n",
       "      <td>0.775048</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.776276</td>\n",
       "      <td>0.776173</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.073660      0.010755         0.015565        0.003091   \n",
       "1       0.207638      0.027449         0.026752        0.001558   \n",
       "2       0.396040      0.023567         0.055455        0.013361   \n",
       "3       0.085616      0.015366         0.014412        0.001526   \n",
       "4       0.277640      0.049556         0.031804        0.005028   \n",
       "\n",
       "   param_max_depth  param_n_estimators                                 params  \\\n",
       "0              1.0                  10   {'max_depth': 1, 'n_estimators': 10}   \n",
       "1              1.0                  50   {'max_depth': 1, 'n_estimators': 50}   \n",
       "2              1.0                 100  {'max_depth': 1, 'n_estimators': 100}   \n",
       "3              2.0                  10   {'max_depth': 2, 'n_estimators': 10}   \n",
       "4              2.0                  50   {'max_depth': 2, 'n_estimators': 50}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.760748           0.760715           0.760715           0.760715   \n",
       "1           0.760748           0.760715           0.760715           0.760715   \n",
       "2           0.760748           0.760715           0.760715           0.760715   \n",
       "3           0.778627           0.779143           0.776686           0.779962   \n",
       "4           0.776034           0.775730           0.775048           0.777778   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.760715         0.760722        0.000013               10  \n",
       "1           0.760715         0.760722        0.000013               10  \n",
       "2           0.760715         0.760722        0.000013               10  \n",
       "3           0.777778         0.778439        0.001128                7  \n",
       "4           0.776276         0.776173        0.000902                8  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8a58cf5",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd95c7599acf8c75",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best forest uses depth None with 100 trees.\n"
     ]
    }
   ],
   "source": [
    "best_estimators = None\n",
    "best_depth = None\n",
    "### BEGIN SOLUTION\n",
    "best_params = results_df.nsmallest(1, 'rank_test_score')['params'].values[0]\n",
    "best_estimators = 100\n",
    "best_depth = None\n",
    "### END SOLUTION\n",
    "#Answer test\n",
    "print(f'The best forest uses depth {best_depth} with {best_estimators} trees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "907df7a8",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-94204fdc44ec7ff1",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "best_estimators_ = 100\n",
    "best_depth_ = None\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "assert best_depth == best_depth_\n",
    "assert best_estimators == best_estimators_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a128a5ba",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0563ff234c8e06d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:)\n",
    "\n",
    "### Question 5\n",
    "\n",
    "While this model seems to have slight improvement over the original, you may want to retrain the model on the full data set with these optimal parameters and see if the test score improves over the cross-validated version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f19a1ea",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b4f84ff67ff2010",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on full training set: 0.9999181021539133\n",
      "Accuracy on test set: 0.8550487265580214\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=best_estimators, max_depth=best_depth, random_state=22)\n",
    "forest.fit(X_train_transformed, y_train)\n",
    "print(f'Accuracy on full training set: {forest.score(X_train_transformed, y_train)}')\n",
    "print(f'Accuracy on test set: {forest.score(X_test_transformed, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c7151",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1893a2faf2a79004",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Did the grid search improve the performance on the testing data even if only by a little?  Assign your answer choice `a`, `b`, `c` or `d` as a string to `ans5` below.\n",
    "\n",
    "```\n",
    "a. There is no performance increase from hyperparameter tuning.\n",
    "b. There is a slight performance increase with the new hyperparameters.\n",
    "c. The baseline model performs better than both.\n",
    "d. Cannot determine.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f34f0b56",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-83fe59d3038b5c4d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "ans5 = None\n",
    "### BEGIN SOLUTION\n",
    "ans5 = 'b'\n",
    "### END SOLUTION\n",
    "#Answer test\n",
    "print(type(ans5))\n",
    "print(ans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7a64494",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8676fc8fa4d81361",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ans5_ = 'b'\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ans5 == ans5_, 'Make sure to compare to the original test score and forest model in problem 4.'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f21f96",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7a2b12a1289377d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:)\n",
    "\n",
    "### Question 6\n",
    "\n",
    "Below, a DataFrame `importance_df` reports the results of the feature importances in the random forest model.  Use this to determine the most important feature in determining whether an individual earns more than 50,000 dollars a year. \n",
    "\n",
    "Assign the most important feature according to the `DataFrame` as a string to `most_important_feature`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23275d6d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-24943515ea430976",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# You may execute this cell on your local machine. Answer the next cell based on the image below.\n",
    "#importance_df = pd.DataFrame({'features': transformer.get_feature_names(), 'importance': forest.feature_importances_})\n",
    "#importance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e90c2-3c9e-4884-98f7-b28c4c6097e4",
   "metadata": {},
   "source": [
    "![Important Features](./important-features.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0078f97",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-deca959e4cab7e2d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "The most imporant feature is onehotencoder__workclass_Private.\n"
     ]
    }
   ],
   "source": [
    "most_important_feature = None\n",
    "### BEGIN SOLUTION\n",
    "most_important_feature = 'onehotencoder__workclass_Private'\n",
    "### END SOLUTION\n",
    "#Answer test\n",
    "print(type(most_important_feature))\n",
    "print(f'The most imporant feature is {most_important_feature}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c64e3b4f",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a443d00a68a2a868",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "most_important_feature_ = 'onehotencoder__workclass_Private'\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "assert most_important_feature == most_important_feature_, 'Make sure to use the exact spelling from X.'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f5c426",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d62b44271114c0e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Summary\n",
    "One of the things to note here is the nature of the features selected as most important.  The `.feature_importances_` attribute biases continuous features as they are more likely to be used to split more frequently than a binary categorical variable.  There are different approaches to understanding the importance of features, including permuataion feature importance measures that attempt to deal with these shortcomings.\n",
    "\n",
    "You are encouraged to explore the [documentation with scikit-learn](https://scikit-learn.org/stable/inspection.html) and compare the results of feature importance interpretation using both methods.  These issues are of importance for more black box-type models and serve as an active area of research for interpreting 'black box' models. There are numerous other packages that implement alternative interpretation approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8babd99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
